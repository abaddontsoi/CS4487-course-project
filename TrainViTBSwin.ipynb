{"cells":[{"cell_type":"markdown","id":"324690f2","metadata":{"id":"324690f2"},"source":["Group: 9\n","\n","Members:"]},{"cell_type":"code","execution_count":null,"id":"DuDb1rSVET0p","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":894,"status":"ok","timestamp":1764680198258,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"DuDb1rSVET0p","outputId":"642f2850-6b7a-4658-a381-6c73a18f225d"},"outputs":[],"source":["!rm -r data/\n","!rm -r __MACOSX/\n","!rm -r test/\n","!rm -r train/\n","!rm -r valid/\n","!rm -r 0_real/\n","!rm -r 1_fake/\n","!rm data.*\n","!rm README.*"]},{"cell_type":"code","execution_count":null,"id":"mOeyl6ZQ8ZSw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1764680260932,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"mOeyl6ZQ8ZSw","outputId":"988ee94c-3c30-4d2b-8451-af66ec0d9953"},"outputs":[],"source":["!rm -r __MACOSX/\n","!rm -r AIGC-Detection-Dataset-2025"]},{"cell_type":"code","execution_count":null,"id":"tkjj6X96EX72","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45588,"status":"ok","timestamp":1764680306522,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"tkjj6X96EX72","outputId":"00f82a25-3dd4-45ec-84fd-a1225b324323"},"outputs":[],"source":["!unzip ./data.zip"]},{"cell_type":"code","execution_count":null,"id":"a8d62aae","metadata":{"executionInfo":{"elapsed":14405,"status":"ok","timestamp":1764680320958,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"a8d62aae"},"outputs":[],"source":["import os\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","from timm import create_model\n","import shutil\n","from pathlib import Path\n","import random\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","import numpy as np\n","import csv, json\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"id":"E0FxXiYJYxAB","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1764680320961,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"E0FxXiYJYxAB"},"outputs":[],"source":["# Split the training dataset\n","def split_train_to_val(source_dir, val_ratio=0.2, seed=42):\n","    source_dir = Path(source_dir)\n","    val_dir = source_dir.parent / \"val\"\n","\n","    random.seed(seed)\n","\n","    # Define class subdirectories\n","    classes = [\"0_real\", \"1_fake\"]\n","\n","    for class_name in classes:\n","        train_class_dir = source_dir / class_name\n","        val_class_dir = val_dir / class_name\n","\n","        if not train_class_dir.exists():\n","            print(f\"Warning: {train_class_dir} does not exist. Skipping.\")\n","            continue\n","\n","        # Create validation directory\n","        val_class_dir.mkdir(parents=True, exist_ok=True)\n","\n","        # Get all image files\n","        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}\n","        files = [f for f in train_class_dir.iterdir()\n","                if f.suffix.lower() in image_extensions and f.is_file()]\n","\n","        if len(files) == 0:\n","            print(f\"No images found in {train_class_dir}\")\n","            continue\n","\n","        # Calculate number to move\n","        num_to_move = max(1, int(len(files) * val_ratio))  # at least 1 image\n","        print(f\"Moving {num_to_move}/{len(files)} images from {class_name} to validation\")\n","\n","        # Randomly select files\n","        files_to_move = random.sample(files, num_to_move)\n","\n","        # Move them\n","        for file_path in files_to_move:\n","            dest_path = val_class_dir / file_path.name\n","            shutil.move(str(file_path), str(dest_path))\n","\n","    print(f\"\\nDone! Validation set created at: {val_dir}\")"]},{"cell_type":"code","execution_count":null,"id":"PoQEGiztY9U0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1764680321901,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"PoQEGiztY9U0","outputId":"ccf39f2b-a066-46f6-8de7-d24b5e59f6c9"},"outputs":[],"source":["split_train_to_val('data/train', val_ratio=0.25, seed=42)"]},{"cell_type":"code","execution_count":null,"id":"0a68bbab","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1764680321915,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"0a68bbab"},"outputs":[],"source":["class data_loader(Dataset):\n","    def __init__(self, data_dir):\n","\n","        real = os.path.join(data_dir, '0_real')\n","        fake = os.path.join(data_dir, '1_fake')\n","\n","        file_names_real = os.listdir(real)\n","        file_names_fake = os.listdir(fake)\n","\n","        self.full_filenames_real = [os.path.join(real, f) for f in file_names_real]\n","        self.full_filenames_fake = [os.path.join(fake, f) for f in file_names_fake]\n","        self.full_filenames = self.full_filenames_real + self.full_filenames_fake\n","\n","        self.labels_real = [0 for _ in file_names_real]\n","        self.labels_fake = [1 for _ in file_names_fake]\n","        self.labels = self.labels_real + self.labels_fake\n","\n","        self.transform_original = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","        ])\n","        \n","        # Data augmentation\n","        self.transform_aug = transforms.Compose([\n","            transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.RandomRotation(30),\n","            transforms.RandAugment(num_ops=2, magnitude=9),\n","            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n","            transforms.ToTensor(),\n","            transforms.RandomErasing(p=0.25, scale=(0.02, 0.15), ratio=(0.3, 3.3), value='random'),\n","            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","        ])\n","\n","    def __len__(self):\n","        return len(self.full_filenames)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.full_filenames[idx]).convert(\"RGB\")\n","        image_aug = self.transform_aug(image)\n","        image_original = self.transform_original(image)\n","        label = self.labels[idx]\n","        return image_original, image_aug, label\n"]},{"cell_type":"code","execution_count":null,"id":"d2f9c4d5","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1764680321921,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"d2f9c4d5"},"outputs":[],"source":["# ===============================\n","# Neural NetWork\n","# ===============================\n","class CNN(nn.Module):\n","    def __init__(self, pretrained=True, freeze_backbone=True, dropout=0.3):\n","        super(CNN, self).__init__()\n","\n","        # ViT-B\n","        self.vit = create_model('vit_base_patch16_224', pretrained=pretrained, num_classes=0)  # 768-dim\n","        # Swin-B\n","        self.swin = create_model('swin_base_patch4_window7_224', pretrained=pretrained, num_classes=0)  # 1024-dim\n","\n","        # Freeze backbones\n","        if freeze_backbone:\n","            for param in self.vit.parameters():\n","                param.requires_grad = False\n","            for param in self.swin.parameters():\n","                param.requires_grad = False\n","\n","\n","        # Fusion MLP: 768 + 1024\n","        self.fusion = nn.Sequential(\n","            # 768 + 1024 → 512\n","            nn.Linear(768 + 1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout),\n","            # 512 → 128\n","            nn.Linear(512, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout),\n","            # 128 → 2\n","            nn.Linear(128, 2)  # 2 classes: real vs AIGC\n","        )\n","\n","    def forward(self, x):\n","        # Extract features with both ViT and Swin\n","        vit_feat = self.vit(x)\n","        swin_feat = self.swin(x)\n","\n","        # For Swin, forward_features returns [B, H*W, C], B for batch\n","        if len(swin_feat.shape) == 3:\n","            swin_feat = swin_feat.mean(1)  # [B, 1024]\n","\n","        # Concatenate feature vectors\n","        combined = torch.cat([vit_feat, swin_feat], dim=1)  # [B, 768 + 1024]\n","\n","        # Classification result\n","        out = self.fusion(combined)\n","        return out"]},{"cell_type":"code","execution_count":null,"id":"e28df9dd","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1764680390944,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"e28df9dd"},"outputs":[],"source":["# ===============================\n","# Train-Validate\n","# ===============================\n","def main():\n","    data_root = \"data\"\n","    batch_size = 32 \n","    epochs_list = [5, 10, 15]\n","    lr = 3e-5 \n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Training on {device}\")\n","\n","    # For each epochs, reset all settings\n","    for epochs in epochs_list:\n","\n","        metrics_log = {\n","            \"train_loss\": [], \"train_acc\": [], \"train_prec\": [], \"train_rec\": [], \"train_f1\": [],\n","            \"val_acc\": [], \"val_prec\": [], \"val_rec\": [], \"val_f1\": []\n","        }\n","\n","        os.makedirs(\"logs\", exist_ok=True)\n","        csv_path  = f\"logs/vit_swin_training_metrics_{epochs}e.csv\"\n","        json_path = f\"logs/vit_swin_training_metrics_{epochs}e.json\"\n","\n","        train_dataset = data_loader(os.path.join(data_root, \"train\"))\n","        val_dataset = data_loader(os.path.join(data_root, \"val\"))\n","\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n","                                num_workers=4, pin_memory=True, drop_last=True)\n","        val_loader = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n","                                num_workers=4, pin_memory=True)\n","\n","        # Move model to training device\n","        model = CNN().to(device)\n","\n","        # Unfreeze last few blocks\n","        for p in model.vit.blocks[-3:].parameters():\n","            p.requires_grad = True\n","        for p in model.swin.layers[-2:].parameters():\n","            p.requires_grad = True\n","\n","        # Apply AdamW optimizer\n","        optimizer = torch.optim.AdamW(\n","            filter(lambda p: p.requires_grad, model.parameters()),\n","            lr=lr,\n","            weight_decay=1e-4\n","        )\n","        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n","        best_val_f1 = 0.0\n","        best_val_acc = 0.0\n","\n","        for epoch in range(epochs):\n","\n","            model.train()\n","            total_loss = 0.0\n","            train_all_preds = []\n","            train_all_labels = []\n","\n","            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}/{epochs} [Train]\")\n","\n","            for img_clean, img_aug, labels in pbar:\n","                img_clean = img_clean.to(device, non_blocking=True)\n","                img_aug = img_aug.to(device, non_blocking=True)\n","                labels = labels.to(device, non_blocking=True)\n","\n","                optimizer.zero_grad()\n","                logits_clean = model(img_clean)\n","                logits_aug   = model(img_aug)\n","\n","                # Calculate loss\n","                logits = (logits_clean + logits_aug) / 2.0\n","                loss = criterion(logits, labels)\n","                loss.backward()\n","                optimizer.step()\n","\n","                total_loss += loss.item()\n","                preds = logits.argmax(dim=1)\n","\n","                train_all_preds.extend(preds.cpu().numpy())\n","                train_all_labels.extend(labels.cpu().numpy())\n","\n","                pbar.set_postfix({\"Loss\": f\"{total_loss/(epoch+1):.4f}\"})\n","\n","            # Training metrics\n","            train_acc  = accuracy_score(train_all_labels, train_all_preds)\n","            train_prec, train_rec, train_f1, _ = precision_recall_fscore_support(\n","                train_all_labels, train_all_preds, average='macro', zero_division=0\n","            )\n","            avg_train_loss = total_loss / len(train_loader)\n","\n","            # Perform validation\n","            model.eval()\n","            val_all_preds = []\n","            val_all_labels = []\n","\n","            with torch.no_grad():\n","                for img_clean, _, labels in val_loader:\n","                    img_clean = img_clean.to(device)\n","                    labels = labels.to(device)\n","                    logits = model(img_clean)\n","                    preds = logits.argmax(dim=1)\n","                    val_all_preds.extend(preds.cpu().numpy())\n","                    val_all_labels.extend(labels.cpu().numpy())\n","\n","            # Evaluate metrics\n","            val_acc = accuracy_score(val_all_labels, val_all_preds)\n","            val_prec, val_rec, val_f1, _ = precision_recall_fscore_support(\n","                val_all_labels, val_all_preds, average='macro', zero_division=0\n","            )\n","\n","            scheduler.step()\n","\n","            # Save model\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                best_val_acc = val_acc\n","                torch.save(model.state_dict(), \"model_best.pth\")\n","                print(f\"Saving best model\")\n","\n","            # Logging metrics\n","            metrics_log[\"train_loss\"].append(avg_train_loss)\n","            metrics_log[\"train_acc\"].append(train_acc)\n","            metrics_log[\"train_prec\"].append(train_prec)\n","            metrics_log[\"train_rec\"].append(train_rec)\n","            metrics_log[\"train_f1\"].append(train_f1)\n","            metrics_log[\"val_acc\"].append(val_acc)\n","            metrics_log[\"val_prec\"].append(val_prec)\n","            metrics_log[\"val_rec\"].append(val_rec)\n","            metrics_log[\"val_f1\"].append(val_f1)\n","\n","            # Print epoch summary\n","            print(f\"\\n=== Epoch {epoch+1:02d}/{epochs} ===\")\n","            print(f\"Train:\\nLoss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | P: {train_prec:.4f} | R: {train_rec:.4f} | F1: {train_f1:.4f}\")\n","            print(f\"Val:\\nAcc: {val_acc:.4f} | P: {val_prec:.4f} | R: {val_rec:.4f} | F1: {val_f1:.4f}\")\n","            print(f\"Best Val:\\nAcc: {best_val_acc:.4f} | F1: {best_val_f1:.4f}\\n\")\n","\n","        # Save metrics to csv and json files\n","        with open(csv_path, mode='w', newline='') as f:\n","            writer = csv.writer(f)\n","            writer.writerow([\"Epoch\", \"Train_Loss\", \"Train_Acc\", \"Train_Prec\", \"Train_Rec\", \"Train_F1\",\n","                            \"Val_Acc\", \"Val_Prec\", \"Val_Rec\", \"Val_F1\"])\n","            for i in range(epochs):\n","                writer.writerow([\n","                    i,\n","                    f\"{metrics_log['train_loss'][i]:.4f}\",\n","                    f\"{metrics_log['train_acc'][i]:.4f}\",\n","                    f\"{metrics_log['train_prec'][i]:.4f}\",\n","                    f\"{metrics_log['train_rec'][i]:.4f}\",\n","                    f\"{metrics_log['train_f1'][i]:.4f}\",\n","                    f\"{metrics_log['val_acc'][i]:.4f}\",\n","                    f\"{metrics_log['val_prec'][i]:.4f}\",\n","                    f\"{metrics_log['val_rec'][i]:.4f}\",\n","                    f\"{metrics_log['val_f1'][i]:.4f}\",\n","                ])\n","\n","        log_to_save = {k: [f\"{v:.6f}\" if isinstance(v, float) else v for v in vals]\n","                    for k, vals in metrics_log.items()}\n","        log_to_save[\"best_val_accuracy\"] = f\"{best_val_acc:.6f}\"\n","        log_to_save[\"best_val_f1\"] = f\"{best_val_f1:.6f}\"\n","        log_to_save[\"total_epochs\"] = epochs\n","\n","        with open(json_path, 'w') as f:\n","            json.dump(log_to_save, f, indent=2)\n","\n","        print(f\"csv saved: {csv_path}\")\n","        print(f\"json saved: {json_path}\")\n","\n","        # Final save per epoch count\n","        torch.save(model.state_dict(), f\"ViTB_Swin_{epochs}e.pth\")\n","        print(f\"Trained with {epochs} epochs\")\n","        print(f\"Final Best Val Accuracy: {best_val_acc:.4f} | Best Val F1: {best_val_f1:.4f}\\n\")"]},{"cell_type":"code","execution_count":null,"id":"62bde9f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53249581,"status":"ok","timestamp":1764733643386,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"62bde9f5","outputId":"83214c84-a97b-4ec3-e8cc-16810d9e1d14"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}

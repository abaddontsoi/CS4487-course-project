{"cells":[{"cell_type":"markdown","id":"324690f2","metadata":{"id":"324690f2"},"source":["Group:\n","\n","Members:"]},{"cell_type":"code","execution_count":null,"id":"AqDP8BErDp9J","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1224,"status":"ok","timestamp":1764565384297,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"AqDP8BErDp9J","outputId":"1d73a797-27c4-4522-f219-e4054d1b59af"},"outputs":[],"source":["# Mount google drive\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"DuDb1rSVET0p","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1087,"status":"ok","timestamp":1764565385382,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"DuDb1rSVET0p","outputId":"ae9c55cb-2cd2-4e69-a968-8f70e54fc54b"},"outputs":[],"source":["!rm -r data/\n","!rm -r __MACOSX/\n","!rm -r test/\n","!rm -r train/\n","!rm -r valid/\n","!rm data.*\n","!rm README.*"]},{"cell_type":"code","execution_count":null,"id":"tg7gtLBDEUXq","metadata":{"executionInfo":{"elapsed":98284,"status":"ok","timestamp":1764565483668,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"tg7gtLBDEUXq"},"outputs":[],"source":["!mkdir data\n","!cp drive/MyDrive/CS4487/data.zip ./data.zip"]},{"cell_type":"code","execution_count":null,"id":"tkjj6X96EX72","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93294,"status":"ok","timestamp":1764565576948,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"tkjj6X96EX72","outputId":"dbbce646-5766-4424-a209-4d83b8b8229c"},"outputs":[],"source":["!unzip ./data.zip"]},{"cell_type":"code","execution_count":null,"id":"a8d62aae","metadata":{"executionInfo":{"elapsed":8833,"status":"ok","timestamp":1764565585783,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"a8d62aae"},"outputs":[],"source":["import os\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","from timm import create_model\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"id":"0a68bbab","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1764565585795,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"0a68bbab"},"outputs":[],"source":["# ===============================\n","# Self-Defined Dataloader\n","# ===============================\n","class data_loader(Dataset):\n","    def __init__(self, data_dir):\n","\n","        real = os.path.join(data_dir, '0_real')\n","        fake = os.path.join(data_dir, '1_fake')\n","\n","        file_names_real = os.listdir(real)\n","        file_names_fake = os.listdir(fake)\n","\n","        self.full_filenames_real = [os.path.join(real, f) for f in file_names_real]\n","        self.full_filenames_fake = [os.path.join(fake, f) for f in file_names_fake]\n","        self.full_filenames = self.full_filenames_real + self.full_filenames_fake\n","\n","        self.labels_real = [0 for _ in file_names_real]\n","        self.labels_fake = [1 for _ in file_names_fake]\n","        self.labels = self.labels_real + self.labels_fake\n","\n","        self.transform_original = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n","        ])\n","\n","        self.transform_aug = transforms.Compose([\n","            transforms.RandomResizedCrop(size=(224, 224)),\n","            transforms.ToTensor(),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomRotation(15),\n","            transforms.RandomResizedCrop(224),\n","            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","        ])\n","\n","    def __len__(self):\n","        return len(self.full_filenames)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.full_filenames[idx]).convert(\"RGB\")\n","        image_aug = self.transform_aug(image)\n","        image_original = self.transform_original(image)\n","        label = self.labels[idx]\n","        return image_original, image_aug, label\n"]},{"cell_type":"code","execution_count":null,"id":"d2f9c4d5","metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1764565585799,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"d2f9c4d5"},"outputs":[],"source":["# ===============================\n","# Neural NetWork\n","# ===============================\n","class CNN(nn.Module):\n","    def __init__(self, pretrained=True, freeze_backbone=True, dropout=0.3):\n","        super(CNN, self).__init__()\n","\n","        # === ViT-B ===\n","        self.vit = create_model('vit_base_patch16_224', pretrained=pretrained, num_classes=0)  # 768-dim\n","        # === Swin-B ===\n","        self.swin = create_model('swin_base_patch4_window7_224', pretrained=pretrained, num_classes=0)  # 1024-dim\n","\n","        # Freeze backbones (recommended for AIGC detection with limited data)\n","        if freeze_backbone:\n","            for param in self.vit.parameters():\n","                param.requires_grad = False\n","            for param in self.swin.parameters():\n","                param.requires_grad = False\n","\n","\n","\n","        # Fusion MLP: 768 + 1024 = 1792 → 512 → 128 → 2\n","        self.fusion = nn.Sequential(\n","            nn.Linear(768 + 1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout),\n","\n","            nn.Linear(512, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout),\n","\n","            nn.Linear(128, 2)  # Exactly 2 classes: real vs synthetic\n","        )\n","\n","    def forward(self, x):\n","        # Extract features\n","        vit_feat = self.vit(x)           # [B, 768]\n","        swin_feat = self.swin(x)         # [B, 1024]\n","\n","        # For Swin, forward_features returns [B, H*W, C] → global avg pool if needed\n","        if len(swin_feat.shape) == 3:\n","            swin_feat = swin_feat.mean(1)  # [B, 1024]\n","\n","        # Concatenate\n","        combined = torch.cat([vit_feat, swin_feat], dim=1)  # [B, 1792]\n","\n","        # Final classification\n","        out = self.fusion(combined)\n","        return out"]},{"cell_type":"code","execution_count":null,"id":"e28df9dd","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1764565658590,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"e28df9dd"},"outputs":[],"source":["# ===============================\n","# Train-Validate (Fixed + High-Performance Version)\n","# ===============================\n","def main():\n","    data_root   = \"data\"\n","    batch_size  = 16          # Smaller batch = better generalization with dual-view\n","    epochs      = 15\n","    lr          = 3e-5        # Lower LR works much better when unfreezing layers\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Training on {device}\")\n","\n","    # ===============================\n","    # Dataset & Dataloader\n","    # ===============================\n","    train_dataset = data_loader(os.path.join(data_root, \"train\"))\n","    val_dataset   = data_loader(os.path.join(data_root, \"val\"))\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n","                              num_workers=4, pin_memory=True, drop_last=True)\n","    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n","                              num_workers=4, pin_memory=True)\n","\n","    # ===============================\n","    # Model + Optimizer + Loss\n","    # ===============================\n","    model = CNN().to(device)\n","\n","    # Unfreeze last few blocks → huge boost!\n","    for p in model.vit.blocks[-3:].parameters():   p.requires_grad = True\n","    for p in model.swin.layers[-2:].parameters():  p.requires_grad = True\n","\n","    optimizer = torch.optim.AdamW(\n","        filter(lambda p: p.requires_grad, model.parameters()),\n","        lr=lr,\n","        weight_decay=1e-4\n","    )\n","    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Magic for AIGC detection\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n","\n","    best_val_acc = 0.0\n","\n","    for epoch in range(epochs):\n","        # ------------------- Training -------------------\n","        model.train()\n","        total_loss = 0.0\n","        train_correct = 0\n","        train_total = 0\n","\n","        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}/{epochs} [Train]\")\n","\n","        for img_clean, img_aug, labels in pbar:\n","            img_clean = img_clean.to(device, non_blocking=True)\n","            img_aug   = img_aug.to(device, non_blocking=True)\n","            labels    = labels.to(device, non_blocking=True)\n","\n","            optimizer.zero_grad()\n","\n","            # Forward both views\n","            logits_clean = model(img_clean)\n","            logits_aug   = model(img_aug)\n","\n","            loss = criterion(logits_clean, labels) + criterion(logits_aug, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            pred = (logits_clean + logits_aug).argmax(dim=1) / 2  # Ensemble both views\n","            train_correct += (pred == labels).sum().item()\n","            train_total += labels.size(0)\n","\n","            pbar.set_postfix({\n","                \"Loss\": f\"{total_loss/(pbar.n+1)}\",\n","                \"Acc\": f\"{train_correct/train_total:.4f}\"\n","            })\n","\n","        # ------------------- Validation -------------------\n","        model.eval()\n","        val_correct = 0\n","        val_total = 0\n","\n","        with torch.no_grad():\n","            for img_clean, img_aug, labels in val_loader:\n","                img_clean = img_clean.to(device)\n","                labels = labels.to(device)\n","\n","                logits = model(img_clean)  # Only clean images for validation\n","                pred = logits.argmax(dim=1)\n","\n","                val_correct += (pred == labels).sum().item()\n","                val_total += labels.size(0)\n","\n","        val_acc = val_correct / val_total\n","\n","        # Scheduler step\n","        scheduler.step()\n","\n","        # Save best model\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            torch.save(model.state_dict(), \"model.pth\")\n","            print(f\"New best model saved! Val Acc: {val_acc:.4f}\")\n","\n","        print(f\"Epoch {epoch+1:02d} | \"\n","              f\"Train Loss: {total_loss/len(train_loader):.4f} | \"\n","              f\"Train Acc: {train_correct/train_total:.4f} | \"\n","              f\"Val Acc: {val_acc:.4f} | \"\n","              f\"Best Val: {best_val_acc:.4f}\")\n","\n","    # Final save\n","    torch.save(model.state_dict(), \"model_final.pth\")\n","    print(f\"\\nTraining completed! Best Validation Accuracy: {best_val_acc:.4f}\")\n","    print(\"Models saved as 'model.pth' (recommended) and 'model_final.pth'\")"]},{"cell_type":"code","execution_count":null,"id":"62bde9f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62bde9f5","outputId":"3ee68f53-334a-4160-8c48-aec79780fdf5"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"id":"w2_6n18xLSKc","metadata":{"id":"w2_6n18xLSKc"},"outputs":[],"source":["!cp model.pth drive/MyDrive/CS4487/model.pth"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}

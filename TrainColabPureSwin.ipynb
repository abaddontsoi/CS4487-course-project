{"cells":[{"cell_type":"markdown","id":"324690f2","metadata":{"id":"324690f2"},"source":["Group:\n","\n","Members:"]},{"cell_type":"markdown","source":[],"metadata":{"id":"gWLoYx2Q4bBQ"},"id":"gWLoYx2Q4bBQ"},{"cell_type":"code","source":["# Mount google drive\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJSaQkbkbPaj","executionInfo":{"status":"ok","timestamp":1764680173000,"user_tz":-480,"elapsed":22992,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"}},"outputId":"97a20500-16de-4dd1-dc76-a83550b85643"},"id":"dJSaQkbkbPaj","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!rm -r data/\n","!rm -r __MACOSX/\n","!rm -r test/\n","!rm -r train/\n","!rm -r valid/\n","!rm -r 0_real/\n","!rm -r 1_fake/\n","!rm data.*\n","!rm README.*"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mNWolxsbRiH","executionInfo":{"status":"ok","timestamp":1764680173888,"user_tz":-480,"elapsed":885,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"}},"outputId":"67be5bcd-b1a5-4a21-9c13-437218079c06"},"id":"7mNWolxsbRiH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove 'data/': No such file or directory\n","rm: cannot remove '__MACOSX/': No such file or directory\n","rm: cannot remove 'test/': No such file or directory\n","rm: cannot remove 'train/': No such file or directory\n","rm: cannot remove 'valid/': No such file or directory\n","rm: cannot remove '0_real/': No such file or directory\n","rm: cannot remove '1_fake/': No such file or directory\n","rm: cannot remove 'data.*': No such file or directory\n","rm: cannot remove 'README.*': No such file or directory\n"]}]},{"cell_type":"code","source":["!mkdir data\n","!cp drive/MyDrive/CS4487/data.zip ./data.zip"],"metadata":{"id":"9a4-FKc6bS8f"},"id":"9a4-FKc6bS8f","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -r __MACOSX/\n","!rm -r AIGC-Detection-Dataset-2025"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92hTmxWJbUSL","executionInfo":{"status":"ok","timestamp":1764680255405,"user_tz":-480,"elapsed":166,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"}},"outputId":"efa567fc-4a21-49e1-86be-6659b026ddda"},"id":"92hTmxWJbUSL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove '__MACOSX/': No such file or directory\n","rm: cannot remove 'AIGC-Detection-Dataset-2025': No such file or directory\n"]}]},{"cell_type":"code","execution_count":null,"id":"0b80b40d","metadata":{"id":"0b80b40d"},"outputs":[],"source":["!rm -rf data/\n","!rm -rf test/\n","!rm -rf __MACOSX/\n","!unzip data.zip"]},{"cell_type":"code","execution_count":null,"id":"a8d62aae","metadata":{"id":"a8d62aae"},"outputs":[],"source":["import os\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","from timm import create_model\n","import shutil\n","from pathlib import Path\n","import random\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","import numpy as np\n","import csv, json\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"id":"67cacf09","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67cacf09","executionInfo":{"status":"ok","timestamp":1764680317008,"user_tz":-480,"elapsed":746,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"}},"outputId":"26092f6e-db4e-41c0-bc77-30393daea68c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Moving 3750/25000 images from 0_real to validation\n","Moving 3750/25000 images from 1_fake to validation\n","\n","Done! Validation set created at: data/val\n"]}],"source":["import os\n","import shutil\n","from pathlib import Path\n","import random\n","import argparse\n","\n","def split_train_to_val(source_dir, val_ratio=0.2, seed=42):\n","    source_dir = Path(source_dir)\n","    val_dir = source_dir.parent / \"val\"\n","\n","    random.seed(seed)\n","\n","    # Define class subdirectories\n","    classes = [\"0_real\", \"1_fake\"]\n","\n","    for class_name in classes:\n","        train_class_dir = source_dir / class_name\n","        val_class_dir = val_dir / class_name\n","\n","        if not train_class_dir.exists():\n","            print(f\"Warning: {train_class_dir} does not exist. Skipping.\")\n","            continue\n","\n","        # Create validation directory\n","        val_class_dir.mkdir(parents=True, exist_ok=True)\n","\n","        # Get all image files\n","        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}\n","        files = [f for f in train_class_dir.iterdir()\n","                if f.suffix.lower() in image_extensions and f.is_file()]\n","\n","        if len(files) == 0:\n","            print(f\"No images found in {train_class_dir}\")\n","            continue\n","\n","        # Calculate number to move\n","        num_to_move = max(1, int(len(files) * val_ratio))  # at least 1 image\n","        print(f\"Moving {num_to_move}/{len(files)} images from {class_name} to validation\")\n","\n","        # Randomly select files\n","        files_to_move = random.sample(files, num_to_move)\n","\n","        # Move them\n","        for file_path in files_to_move:\n","            dest_path = val_class_dir / file_path.name\n","            shutil.move(str(file_path), str(dest_path))\n","            # print(f\"Moved: {file_path.name} → {dest_path}\")\n","\n","    print(f\"\\nDone! Validation set created at: {val_dir}\")\n","\n","split_train_to_val(\"data/train\", val_ratio=0.15, seed=42)"]},{"cell_type":"code","execution_count":null,"id":"0a68bbab","metadata":{"id":"0a68bbab"},"outputs":[],"source":["class data_loader(Dataset):\n","    def __init__(self, data_dir):\n","\n","        real = os.path.join(data_dir, '0_real')\n","        fake = os.path.join(data_dir, '1_fake')\n","\n","        file_names_real = os.listdir(real)\n","        file_names_fake = os.listdir(fake)\n","\n","        self.full_filenames_real = [os.path.join(real, f) for f in file_names_real]\n","        self.full_filenames_fake = [os.path.join(fake, f) for f in file_names_fake]\n","        self.full_filenames = self.full_filenames_real + self.full_filenames_fake\n","\n","        self.labels_real = [0 for _ in file_names_real]\n","        self.labels_fake = [1 for _ in file_names_fake]\n","        self.labels = self.labels_real + self.labels_fake\n","\n","        self.transform_original = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","        ])\n","\n","        self.transform_aug = transforms.Compose([\n","            transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.RandomRotation(30),\n","            transforms.RandAugment(num_ops=2, magnitude=9),\n","            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n","            transforms.ToTensor(),\n","            transforms.RandomErasing(p=0.25, scale=(0.02, 0.15), ratio=(0.3, 3.3), value='random'),\n","            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","        ])\n","\n","    def __len__(self):\n","        return len(self.full_filenames)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.full_filenames[idx]).convert(\"RGB\")\n","        image_aug = self.transform_aug(image)\n","        image_original = self.transform_original(image)\n","        label = self.labels[idx]\n","        return image_original, image_aug, label\n"]},{"cell_type":"code","execution_count":null,"id":"d2f9c4d5","metadata":{"id":"d2f9c4d5"},"outputs":[],"source":["# ===============================\n","# Neural NetWork\n","# ===============================\n","class CNN(nn.Module):\n","    def __init__(self, pretrained=True, freeze_backbone=True, dropout=0.3):\n","        super(CNN, self).__init__()\n","        # === Swin-B ===\n","        self.swin = create_model('swin_base_patch4_window7_224', pretrained=pretrained, num_classes=0)  # 1024-dim\n","\n","        # Freeze backbones (recommended for AIGC detection with limited data)\n","        if freeze_backbone:\n","            for param in self.swin.parameters():\n","                param.requires_grad = False\n","\n","        self.fusion = nn.Sequential(\n","            nn.Linear(1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout),\n","\n","            nn.Linear(512, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(dropout),\n","\n","            nn.Linear(128, 2)  # Exactly 2 classes: real vs synthetic\n","        )\n","\n","    def forward(self, x):\n","        # Extract features\n","        swin_feat = self.swin(x)         # [B, 1024]\n","\n","        # For Swin, forward_features returns [B, H*W, C] → global avg pool if needed\n","        if len(swin_feat.shape) == 3:\n","            swin_feat = swin_feat.mean(1)  # [B, 1024]\n","\n","        # Final classification\n","        out = self.fusion(swin_feat)\n","        return out"]},{"cell_type":"code","execution_count":null,"id":"e28df9dd","metadata":{"id":"e28df9dd"},"outputs":[],"source":["# ===============================\n","# Train-Validate\n","# ===============================\n","def main():\n","    data_root = \"data\"\n","    batch_size = 32 # Smaller batch = better generalization with dual-view\n","    epochs_list = [5, 10, 15]\n","    lr = 3e-5 # Lower LR works much better when unfreezing layers\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Training on {device}\")\n","\n","    # For each epochs, reset all settings\n","    for epochs in epochs_list:\n","        # ===============================\n","        # Metrics Logging Setup\n","        # ===============================\n","        metrics_log = {\n","            \"train_loss\": [],\n","            \"train_acc\": [],\n","            \"train_prec\": [],\n","            \"train_rec\": [],\n","            \"train_f1\": [],\n","            \"val_acc\": [],\n","            \"val_prec\": [],\n","            \"val_rec\": [],\n","            \"val_f1\": []\n","        }\n","\n","        os.makedirs(\"logs\", exist_ok=True)\n","        csv_path  = f\"logs/pure_swin_training_metrics_{epochs}e.csv\"\n","        json_path = f\"logs/pure_swin_training_metrics_{epochs}e.json\"\n","        # ===============================\n","        # Dataset & Dataloader\n","        # ===============================\n","        train_dataset = data_loader(os.path.join(data_root, \"train\"))\n","        val_dataset = data_loader(os.path.join(data_root, \"val\"))\n","\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n","                                num_workers=4 if torch.cuda.is_available() else 0, pin_memory=True, drop_last=True)\n","        val_loader = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n","                                num_workers=4 if torch.cuda.is_available() else 0, pin_memory=True)\n","\n","        # ===============================\n","        # Model + Optimizer + Loss\n","        # ===============================\n","        model = CNN().to(device)\n","\n","        # Unfreeze last few blocks\n","        for p in model.swin.layers[-2:].parameters():\n","            p.requires_grad = True\n","\n","        optimizer = torch.optim.AdamW(\n","            filter(lambda p: p.requires_grad, model.parameters()),\n","            lr=lr,\n","            weight_decay=1e-4\n","        )\n","        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n","        best_val_f1 = 0.0\n","        best_val_acc = 0.0\n","\n","        for epoch in range(epochs):\n","            # ------------------- Training -------------------\n","            model.train()\n","            total_loss = 0.0\n","            train_all_preds = []\n","            train_all_labels = []\n","\n","            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1:02d}/{epochs} [Train]\")\n","\n","            for img_clean, img_aug, labels in pbar:\n","                img_clean = img_clean.to(device, non_blocking=True)\n","                img_aug = img_aug.to(device, non_blocking=True)\n","                labels = labels.to(device, non_blocking=True)\n","\n","                optimizer.zero_grad()\n","                logits_clean = model(img_clean)\n","                logits_aug   = model(img_aug)\n","\n","                # Proper dual-view ensembling\n","                logits = (logits_clean + logits_aug) / 2.0\n","                loss = criterion(logits, labels)\n","                loss.backward()\n","                optimizer.step()\n","\n","                total_loss += loss.item()\n","                preds = logits.argmax(dim=1)\n","\n","                train_all_preds.extend(preds.cpu().numpy())\n","                train_all_labels.extend(labels.cpu().numpy())\n","\n","                pbar.set_postfix({\"Loss\": f\"{total_loss/(epoch+1):.4f}\"})\n","\n","            # Training metrics\n","            train_acc  = accuracy_score(train_all_labels, train_all_preds)\n","            train_prec, train_rec, train_f1, _ = precision_recall_fscore_support(\n","                train_all_labels, train_all_preds, average='macro', zero_division=0\n","            )\n","            avg_train_loss = total_loss / len(train_loader)\n","\n","            # ------------------- Validation -------------------\n","            model.eval()\n","            val_all_preds = []\n","            val_all_labels = []\n","\n","            with torch.no_grad():\n","                for img_clean, _, labels in val_loader:\n","                    img_clean = img_clean.to(device)\n","                    labels = labels.to(device)\n","                    logits = model(img_clean)\n","                    preds = logits.argmax(dim=1)\n","                    val_all_preds.extend(preds.cpu().numpy())\n","                    val_all_labels.extend(labels.cpu().numpy())\n","\n","            val_acc = accuracy_score(val_all_labels, val_all_preds)\n","            val_prec, val_rec, val_f1, _ = precision_recall_fscore_support(val_all_labels, val_all_preds, average='macro', zero_division=0)\n","\n","            scheduler.step()\n","\n","            # Save best model (by macro F1)\n","            if val_f1 > best_val_f1:\n","                best_val_f1 = val_f1\n","                best_val_acc = val_acc\n","                torch.save(model.state_dict(), \"model_best.pth\")\n","                print(f\"New best model saved! Val F1: {val_f1:.4f} | Val Acc: {val_acc:.4f}\")\n","\n","            # ===============================\n","            # Log metrics for this epoch\n","            # ===============================\n","            metrics_log[\"train_loss\"].append(avg_train_loss)\n","            metrics_log[\"train_acc\"].append(train_acc)\n","            metrics_log[\"train_prec\"].append(train_prec)\n","            metrics_log[\"train_rec\"].append(train_rec)\n","            metrics_log[\"train_f1\"].append(train_f1)\n","            metrics_log[\"val_acc\"].append(val_acc)\n","            metrics_log[\"val_prec\"].append(val_prec)\n","            metrics_log[\"val_rec\"].append(val_rec)\n","            metrics_log[\"val_f1\"].append(val_f1)\n","\n","            # Print epoch summary\n","            print(f\"\\n=== Epoch {epoch+1:02d}/{epochs} ===\")\n","            print(f\"Train → Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | P: {train_prec:.4f} | R: {train_rec:.4f} | F1: {train_f1:.4f}\")\n","            print(f\"Val   → Acc: {val_acc:.4f} | P: {val_prec:.4f} | R: {val_rec:.4f} | F1: {val_f1:.4f}\")\n","            print(f\"Best Val → Acc: {best_val_acc:.4f} | F1: {best_val_f1:.4f}\\n\")\n","\n","        # ===============================\n","        # Save Metrics to CSV & JSON\n","        # ===============================\n","        # CSV\n","        with open(csv_path, mode='w', newline='') as f:\n","            writer = csv.writer(f)\n","            writer.writerow([\"Epoch\", \"Train_Loss\", \"Train_Acc\", \"Train_Prec\", \"Train_Rec\", \"Train_F1\",\n","                            \"Val_Acc\", \"Val_Prec\", \"Val_Rec\", \"Val_F1\"])\n","            for i in range(epochs):\n","                writer.writerow([\n","                    i,\n","                    f\"{metrics_log['train_loss'][i]:.4f}\",\n","                    f\"{metrics_log['train_acc'][i]:.4f}\",\n","                    f\"{metrics_log['train_prec'][i]:.4f}\",\n","                    f\"{metrics_log['train_rec'][i]:.4f}\",\n","                    f\"{metrics_log['train_f1'][i]:.4f}\",\n","                    f\"{metrics_log['val_acc'][i]:.4f}\",\n","                    f\"{metrics_log['val_prec'][i]:.4f}\",\n","                    f\"{metrics_log['val_rec'][i]:.4f}\",\n","                    f\"{metrics_log['val_f1'][i]:.4f}\",\n","                ])\n","\n","        # JSON (extra backup + easy to load later)\n","        log_to_save = {k: [f\"{v:.6f}\" if isinstance(v, float) else v for v in vals]\n","                    for k, vals in metrics_log.items()}\n","        log_to_save[\"best_val_accuracy\"] = f\"{best_val_acc:.6f}\"\n","        log_to_save[\"best_val_f1\"] = f\"{best_val_f1:.6f}\"\n","        log_to_save[\"total_epochs\"] = epochs\n","\n","        with open(json_path, 'w') as f:\n","            json.dump(log_to_save, f, indent=2)\n","\n","        print(f\"All metrics saved!\")\n","        print(f\"   → CSV : {csv_path}\")\n","        print(f\"   → JSON: {json_path}\")\n","        print(f\"Final Best Val Accuracy: {best_val_acc:.4f} | Best Val F1: {best_val_f1:.4f}\\n{'='*60}\\n\")\n","\n","        # Final save per epoch count\n","        torch.save(model.state_dict(), f\"drive/MyDrive/CS4487/Swin_{epochs}e.pth\")\n","        print(f\"Training with {epochs} epochs finished!\")\n","        print(f\"Final Best Val Accuracy: {best_val_acc:.4f} | Best Val F1: {best_val_f1:.4f}\\n\")"]},{"cell_type":"code","execution_count":null,"id":"62bde9f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62bde9f5","executionInfo":{"status":"ok","timestamp":1764719259627,"user_tz":-480,"elapsed":38862263,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"}},"outputId":"3ef0c393-b2d6-4fa5-a018-831641cee7ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training on cuda\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 01/5 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=323.8310]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9931 | Val Acc: 0.9931\n","\n","=== Epoch 01/5 ===\n","Train → Loss: 0.2438 | Acc: 0.9805 | P: 0.9807 | R: 0.9805 | F1: 0.9805\n","Val   → Acc: 0.9931 | P: 0.9931 | R: 0.9931 | F1: 0.9931\n","Best Val → Acc: 0.9931 | F1: 0.9931\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 02/5 [Train]: 100%|██████████| 1328/1328 [20:45<00:00,  1.07it/s, Loss=144.2597]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9971 | Val Acc: 0.9971\n","\n","=== Epoch 02/5 ===\n","Train → Loss: 0.2173 | Acc: 0.9955 | P: 0.9955 | R: 0.9955 | F1: 0.9955\n","Val   → Acc: 0.9971 | P: 0.9971 | R: 0.9971 | F1: 0.9971\n","Best Val → Acc: 0.9971 | F1: 0.9971\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 03/5 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=93.4237]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9975 | Val Acc: 0.9975\n","\n","=== Epoch 03/5 ===\n","Train → Loss: 0.2110 | Acc: 0.9980 | P: 0.9980 | R: 0.9980 | F1: 0.9980\n","Val   → Acc: 0.9975 | P: 0.9975 | R: 0.9975 | F1: 0.9975\n","Best Val → Acc: 0.9975 | F1: 0.9975\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 04/5 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=68.8027]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9976 | Val Acc: 0.9976\n","\n","=== Epoch 04/5 ===\n","Train → Loss: 0.2072 | Acc: 0.9994 | P: 0.9994 | R: 0.9994 | F1: 0.9994\n","Val   → Acc: 0.9976 | P: 0.9976 | R: 0.9976 | F1: 0.9976\n","Best Val → Acc: 0.9976 | F1: 0.9976\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 05/5 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=54.7292]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9980 | Val Acc: 0.9980\n","\n","=== Epoch 05/5 ===\n","Train → Loss: 0.2061 | Acc: 0.9997 | P: 0.9997 | R: 0.9997 | F1: 0.9997\n","Val   → Acc: 0.9980 | P: 0.9980 | R: 0.9980 | F1: 0.9980\n","Best Val → Acc: 0.9980 | F1: 0.9980\n","\n","All metrics saved!\n","   → CSV : logs/pure_swin_training_metrics_5e.csv\n","   → JSON: logs/pure_swin_training_metrics_5e.json\n","Final Best Val Accuracy: 0.9980 | Best Val F1: 0.9980\n","============================================================\n","\n","Training with 5 epochs finished!\n","Final Best Val Accuracy: 0.9980 | Best Val F1: 0.9980\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 01/10 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=320.1958]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9927 | Val Acc: 0.9927\n","\n","=== Epoch 01/10 ===\n","Train → Loss: 0.2411 | Acc: 0.9809 | P: 0.9810 | R: 0.9809 | F1: 0.9809\n","Val   → Acc: 0.9927 | P: 0.9928 | R: 0.9927 | F1: 0.9927\n","Best Val → Acc: 0.9927 | F1: 0.9927\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 02/10 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=143.9655]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9981 | Val Acc: 0.9981\n","\n","=== Epoch 02/10 ===\n","Train → Loss: 0.2168 | Acc: 0.9952 | P: 0.9952 | R: 0.9952 | F1: 0.9952\n","Val   → Acc: 0.9981 | P: 0.9981 | R: 0.9981 | F1: 0.9981\n","Best Val → Acc: 0.9981 | F1: 0.9981\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 03/10 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=93.7500]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 03/10 ===\n","Train → Loss: 0.2118 | Acc: 0.9973 | P: 0.9973 | R: 0.9973 | F1: 0.9973\n","Val   → Acc: 0.9960 | P: 0.9960 | R: 0.9960 | F1: 0.9960\n","Best Val → Acc: 0.9981 | F1: 0.9981\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 04/10 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=69.3439]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9988 | Val Acc: 0.9988\n","\n","=== Epoch 04/10 ===\n","Train → Loss: 0.2089 | Acc: 0.9982 | P: 0.9982 | R: 0.9982 | F1: 0.9982\n","Val   → Acc: 0.9988 | P: 0.9988 | R: 0.9988 | F1: 0.9988\n","Best Val → Acc: 0.9988 | F1: 0.9988\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 05/10 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=54.9967]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 05/10 ===\n","Train → Loss: 0.2071 | Acc: 0.9990 | P: 0.9990 | R: 0.9990 | F1: 0.9990\n","Val   → Acc: 0.9977 | P: 0.9977 | R: 0.9977 | F1: 0.9977\n","Best Val → Acc: 0.9988 | F1: 0.9988\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 06/10 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=45.4103]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 06/10 ===\n","Train → Loss: 0.2052 | Acc: 0.9996 | P: 0.9996 | R: 0.9996 | F1: 0.9996\n","Val   → Acc: 0.9979 | P: 0.9979 | R: 0.9979 | F1: 0.9979\n","Best Val → Acc: 0.9988 | F1: 0.9988\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 07/10 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=38.6948]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 07/10 ===\n","Train → Loss: 0.2040 | Acc: 0.9998 | P: 0.9998 | R: 0.9998 | F1: 0.9998\n","Val   → Acc: 0.9981 | P: 0.9981 | R: 0.9981 | F1: 0.9981\n","Best Val → Acc: 0.9988 | F1: 0.9988\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 08/10 [Train]: 100%|██████████| 1328/1328 [20:45<00:00,  1.07it/s, Loss=33.8031]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 08/10 ===\n","Train → Loss: 0.2036 | Acc: 0.9999 | P: 0.9999 | R: 0.9999 | F1: 0.9999\n","Val   → Acc: 0.9976 | P: 0.9976 | R: 0.9976 | F1: 0.9976\n","Best Val → Acc: 0.9988 | F1: 0.9988\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 09/10 [Train]: 100%|██████████| 1328/1328 [20:45<00:00,  1.07it/s, Loss=29.9773]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 09/10 ===\n","Train → Loss: 0.2032 | Acc: 0.9999 | P: 0.9999 | R: 0.9999 | F1: 0.9999\n","Val   → Acc: 0.9984 | P: 0.9984 | R: 0.9984 | F1: 0.9984\n","Best Val → Acc: 0.9988 | F1: 0.9988\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=27.0408]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 10/10 ===\n","Train → Loss: 0.2036 | Acc: 0.9999 | P: 0.9999 | R: 0.9999 | F1: 0.9999\n","Val   → Acc: 0.9983 | P: 0.9983 | R: 0.9983 | F1: 0.9983\n","Best Val → Acc: 0.9988 | F1: 0.9988\n","\n","All metrics saved!\n","   → CSV : logs/pure_swin_training_metrics_10e.csv\n","   → JSON: logs/pure_swin_training_metrics_10e.json\n","Final Best Val Accuracy: 0.9988 | Best Val F1: 0.9988\n","============================================================\n","\n","Training with 10 epochs finished!\n","Final Best Val Accuracy: 0.9988 | Best Val F1: 0.9988\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 01/15 [Train]: 100%|██████████| 1328/1328 [20:45<00:00,  1.07it/s, Loss=326.5532]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9912 | Val Acc: 0.9912\n","\n","=== Epoch 01/15 ===\n","Train → Loss: 0.2459 | Acc: 0.9777 | P: 0.9777 | R: 0.9777 | F1: 0.9777\n","Val   → Acc: 0.9912 | P: 0.9913 | R: 0.9912 | F1: 0.9912\n","Best Val → Acc: 0.9912 | F1: 0.9912\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 02/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=144.7476]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9969 | Val Acc: 0.9969\n","\n","=== Epoch 02/15 ===\n","Train → Loss: 0.2180 | Acc: 0.9947 | P: 0.9947 | R: 0.9947 | F1: 0.9947\n","Val   → Acc: 0.9969 | P: 0.9969 | R: 0.9969 | F1: 0.9969\n","Best Val → Acc: 0.9969 | F1: 0.9969\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 03/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=94.9273]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 03/15 ===\n","Train → Loss: 0.2144 | Acc: 0.9966 | P: 0.9966 | R: 0.9966 | F1: 0.9966\n","Val   → Acc: 0.9955 | P: 0.9955 | R: 0.9955 | F1: 0.9955\n","Best Val → Acc: 0.9969 | F1: 0.9969\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 04/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=70.1000]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9979 | Val Acc: 0.9979\n","\n","=== Epoch 04/15 ===\n","Train → Loss: 0.2111 | Acc: 0.9976 | P: 0.9976 | R: 0.9976 | F1: 0.9976\n","Val   → Acc: 0.9979 | P: 0.9979 | R: 0.9979 | F1: 0.9979\n","Best Val → Acc: 0.9979 | F1: 0.9979\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 05/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=55.3864]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 05/15 ===\n","Train → Loss: 0.2085 | Acc: 0.9985 | P: 0.9985 | R: 0.9985 | F1: 0.9985\n","Val   → Acc: 0.9952 | P: 0.9952 | R: 0.9952 | F1: 0.9952\n","Best Val → Acc: 0.9979 | F1: 0.9979\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 06/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=45.6990]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9984 | Val Acc: 0.9984\n","\n","=== Epoch 06/15 ===\n","Train → Loss: 0.2065 | Acc: 0.9990 | P: 0.9990 | R: 0.9990 | F1: 0.9990\n","Val   → Acc: 0.9984 | P: 0.9984 | R: 0.9984 | F1: 0.9984\n","Best Val → Acc: 0.9984 | F1: 0.9984\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 07/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=38.9330]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 07/15 ===\n","Train → Loss: 0.2052 | Acc: 0.9994 | P: 0.9994 | R: 0.9994 | F1: 0.9994\n","Val   → Acc: 0.9955 | P: 0.9955 | R: 0.9955 | F1: 0.9955\n","Best Val → Acc: 0.9984 | F1: 0.9984\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 08/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=33.9171]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9984 | Val Acc: 0.9984\n","\n","=== Epoch 08/15 ===\n","Train → Loss: 0.2043 | Acc: 0.9997 | P: 0.9997 | R: 0.9997 | F1: 0.9997\n","Val   → Acc: 0.9984 | P: 0.9984 | R: 0.9984 | F1: 0.9984\n","Best Val → Acc: 0.9984 | F1: 0.9984\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 09/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=30.1748]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 09/15 ===\n","Train → Loss: 0.2045 | Acc: 0.9996 | P: 0.9996 | R: 0.9996 | F1: 0.9996\n","Val   → Acc: 0.9967 | P: 0.9967 | R: 0.9967 | F1: 0.9967\n","Best Val → Acc: 0.9984 | F1: 0.9984\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/15 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=26.9815]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 10/15 ===\n","Train → Loss: 0.2032 | Acc: 0.9999 | P: 0.9999 | R: 0.9999 | F1: 0.9999\n","Val   → Acc: 0.9983 | P: 0.9983 | R: 0.9983 | F1: 0.9983\n","Best Val → Acc: 0.9984 | F1: 0.9984\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/15 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=24.5109]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 11/15 ===\n","Train → Loss: 0.2030 | Acc: 1.0000 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n","Val   → Acc: 0.9973 | P: 0.9973 | R: 0.9973 | F1: 0.9973\n","Best Val → Acc: 0.9984 | F1: 0.9984\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/15 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=22.4782]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 12/15 ===\n","Train → Loss: 0.2031 | Acc: 0.9999 | P: 0.9999 | R: 0.9999 | F1: 0.9999\n","Val   → Acc: 0.9973 | P: 0.9973 | R: 0.9973 | F1: 0.9973\n","Best Val → Acc: 0.9984 | F1: 0.9984\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/15 [Train]: 100%|██████████| 1328/1328 [20:44<00:00,  1.07it/s, Loss=20.7749]\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved! Val F1: 0.9985 | Val Acc: 0.9985\n","\n","=== Epoch 13/15 ===\n","Train → Loss: 0.2034 | Acc: 0.9999 | P: 0.9999 | R: 0.9999 | F1: 0.9999\n","Val   → Acc: 0.9985 | P: 0.9985 | R: 0.9985 | F1: 0.9985\n","Best Val → Acc: 0.9985 | F1: 0.9985\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=19.2323]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 14/15 ===\n","Train → Loss: 0.2028 | Acc: 1.0000 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n","Val   → Acc: 0.9981 | P: 0.9981 | R: 0.9981 | F1: 0.9981\n","Best Val → Acc: 0.9985 | F1: 0.9985\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/15 [Train]: 100%|██████████| 1328/1328 [20:43<00:00,  1.07it/s, Loss=17.9428]\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Epoch 15/15 ===\n","Train → Loss: 0.2027 | Acc: 1.0000 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n","Val   → Acc: 0.9981 | P: 0.9981 | R: 0.9981 | F1: 0.9981\n","Best Val → Acc: 0.9985 | F1: 0.9985\n","\n","All metrics saved!\n","   → CSV : logs/pure_swin_training_metrics_15e.csv\n","   → JSON: logs/pure_swin_training_metrics_15e.json\n","Final Best Val Accuracy: 0.9985 | Best Val F1: 0.9985\n","============================================================\n","\n","Training with 15 epochs finished!\n","Final Best Val Accuracy: 0.9985 | Best Val F1: 0.9985\n","\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["!cp -r logs/ drive/MyDrive/CS4487/"],"metadata":{"id":"bqNcDaZyp32b"},"id":"bqNcDaZyp32b","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp model_best.pth drive/MyDrive/CS4487/PureSwinBest.pth"],"metadata":{"id":"mwJLYuBXqKln"},"id":"mwJLYuBXqKln","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sf9OlF7vqSFz"},"id":"sf9OlF7vqSFz","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}